{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./creditcardfraud.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appearently, Data are quite clean. Most data columns are encrypted, we can check time column first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud time info:\n",
      "count       492.000000\n",
      "mean      80746.806911\n",
      "std       47835.365138\n",
      "min         406.000000\n",
      "25%       41241.500000\n",
      "50%       75568.500000\n",
      "75%      128483.000000\n",
      "max      170348.000000\n",
      "Name: Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Fraud time info:\")\n",
    "print (df.loc[df[\"Class\"] == 1][\"Time\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, data is very unbalanced, much less fraud than normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal time info:\n",
      "count    284315.000000\n",
      "mean      94838.202258\n",
      "std       47484.015786\n",
      "min           0.000000\n",
      "25%       54230.000000\n",
      "50%       84711.000000\n",
      "75%      139333.000000\n",
      "max      172792.000000\n",
      "Name: Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Normal time info:\")\n",
    "print (df.loc[df[\"Class\"] == 0][\"Time\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'No. of Transctions')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (fig1, fig2) = plt.subplots(2, 1, sharex= True, figsize=(15,5))\n",
    "\n",
    "fig1.hist(df.loc[df[\"Class\"] == 1][\"Time\"], bins = 50)\n",
    "fig1.set_title(\"Fraud\")\n",
    "\n",
    "fig2.hist(df.loc[df[\"Class\"] == 0][\"Time\"], bins = 50)\n",
    "fig2.set_title(\"Normal\")\n",
    "\n",
    "plt.xlabel(\"Time(in sec)\")\n",
    "plt.ylabel(\"No. of Transctions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So fraud times appear to be less uniform, but this could be due to insufficient examples.\n",
    "Next we should check another non-encrypted feature \"Amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# better keep them as 2 separate plots, as the no. of instances are quite diff.\n",
    "f, (fig1, fig2) = plt.subplots(2, 1, sharex= True, figsize=(15,5))\n",
    "\n",
    "fig1.hist(df.loc[df[\"Class\"] == 1][\"Amount\"], bins = 50)\n",
    "fig1.set_title(\"Fraud\")\n",
    "\n",
    "fig2.hist(df.loc[df[\"Class\"] == 0][\"Amount\"], bins = 50)\n",
    "fig2.set_title(\"Normal\")\n",
    "\n",
    "plt.xlabel(\"Amount\")\n",
    "# plt.xlim([0, 5000])\n",
    "plt.ylabel(\"No. of Transctions\")\n",
    "plt.yscale(\"log\")  # use log scale to visualize large but rare amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"Class\"] == 1][\"Amount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent transactions tend to be related with lower expense, this way they don't trigger alerts from this aspect. Also making it hard for customers to notice, if banks fail to identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, (fig1, fig2) = plt.subplots(2, 1, sharex= True, figsize=(15,5))\n",
    "\n",
    "# fig1.scatter(df.loc[df[\"Class\"] == 1][\"Time\"], df.loc[df[\"Class\"] == 1][\"Amount\"], alpha = 0.2)\n",
    "# fig1.set_title(\"Fraud\")\n",
    "\n",
    "# fig2.scatter(df.loc[df[\"Class\"] == 0][\"Time\"], df.loc[df[\"Class\"] == 0][\"Amount\"], alpha = 0.2)\n",
    "# fig2.set_title(\"Normal\")\n",
    "\n",
    "# plt.xlabel(\"Time\")\n",
    "# # plt.xlim([0, 5000])\n",
    "# plt.ylabel(\"Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# v_feature = df.iloc[:, 1:29].columns\n",
    "\n",
    "# plt.figure(figsize=(12, 28*4))\n",
    "# gs = gridspec.GridSpec(28, 1)\n",
    "# for i, cn in enumerate (df[v_feature]):\n",
    "#     ax = plt.subplot(gs[i])  # add a new plot\n",
    "#     sns.distplot( df[cn].loc[df[\"Class\"] == 1], bins = 50)\n",
    "#     sns.distplot( df[cn].loc[df[\"Class\"] == 0], bins = 50)\n",
    "#     ax.set_xlabel(\"\")  # to avoid overlapping\n",
    "#     ax.set_title(\"Feature\" + str(i))\n",
    "# #     ax.set_xlim(-10, 10)  # set limits to identify features of similar distributions\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normalize amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new feature\n",
    "df[\"normAmount\"] = StandardScaler().fit_transform( df[\"Amount\"].values.reshape(-1,1) )\n",
    "df.drop(['Time', 'Amount'], axis = 1, inplace= True)  # axis parameter input needed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Class\"] == 0, \"Normal\"] = 1\n",
    "df.loc[df[\"Class\"] == 1, \"Normal\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Class' : 'Fraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10   ...         V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794   ...    0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974   ...   -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643   ...    0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952   ...    0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074   ...    0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Fraud  normAmount  Normal  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964     1.0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475     1.0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686     1.0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534     1.0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403     1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = df.loc[df['Fraud'] == 1]\n",
    "df_normal = df.loc[df['Normal'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_train = 0.8\n",
    "\n",
    "X_train = df_fraud.sample(frac = frac_train)\n",
    "cnt_fraud = len(X_train)\n",
    "\n",
    "# append 80% of normal to \n",
    "X_train = pd.concat([X_train, df_normal.sample(frac= frac_train)], axis = 0)\n",
    "\n",
    "# rest is test\n",
    "X_test = df.loc[~ df.index.isin(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle randomly\n",
    "X_train = shuffle(X_train)\n",
    "X_test = shuffle(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract target feature\n",
    "y_train = X_train[\"Fraud\"]\n",
    "y_test = X_test[\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Fraud', 'Normal'], axis =1, inplace= True)\n",
    "X_test.drop(['Fraud', 'Normal'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    227452\n",
      "1       394\n",
      "Name: Fraud, dtype: int64\n",
      "0    56863\n",
      "1       98\n",
      "Name: Fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (y_train.value_counts())\n",
    "print (y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "      <td>227846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.958196</td>\n",
       "      <td>1.646457</td>\n",
       "      <td>1.519870</td>\n",
       "      <td>1.414453</td>\n",
       "      <td>1.383504</td>\n",
       "      <td>1.334153</td>\n",
       "      <td>1.242892</td>\n",
       "      <td>1.195017</td>\n",
       "      <td>1.098315</td>\n",
       "      <td>1.089532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772431</td>\n",
       "      <td>0.730943</td>\n",
       "      <td>0.725509</td>\n",
       "      <td>0.624362</td>\n",
       "      <td>0.605838</td>\n",
       "      <td>0.521485</td>\n",
       "      <td>0.482392</td>\n",
       "      <td>0.403746</td>\n",
       "      <td>0.329119</td>\n",
       "      <td>1.007892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.353229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.920445</td>\n",
       "      <td>-0.599402</td>\n",
       "      <td>-0.886796</td>\n",
       "      <td>-0.847125</td>\n",
       "      <td>-0.690418</td>\n",
       "      <td>-0.769129</td>\n",
       "      <td>-0.552255</td>\n",
       "      <td>-0.208185</td>\n",
       "      <td>-0.643202</td>\n",
       "      <td>-0.535908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211726</td>\n",
       "      <td>-0.228490</td>\n",
       "      <td>-0.542285</td>\n",
       "      <td>-0.162012</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.317216</td>\n",
       "      <td>-0.326270</td>\n",
       "      <td>-0.070937</td>\n",
       "      <td>-0.052962</td>\n",
       "      <td>-0.331110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.064758</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>-0.021181</td>\n",
       "      <td>-0.053246</td>\n",
       "      <td>-0.274624</td>\n",
       "      <td>0.040593</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>-0.052193</td>\n",
       "      <td>-0.093538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062041</td>\n",
       "      <td>-0.029558</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>-0.011262</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>-0.051559</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>-0.265271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315281</td>\n",
       "      <td>0.803118</td>\n",
       "      <td>1.024676</td>\n",
       "      <td>0.740101</td>\n",
       "      <td>0.613955</td>\n",
       "      <td>0.399880</td>\n",
       "      <td>0.569928</td>\n",
       "      <td>0.327407</td>\n",
       "      <td>0.595389</td>\n",
       "      <td>0.452657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.186758</td>\n",
       "      <td>0.528388</td>\n",
       "      <td>0.147808</td>\n",
       "      <td>0.439268</td>\n",
       "      <td>0.350726</td>\n",
       "      <td>0.241356</td>\n",
       "      <td>0.090591</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>-0.043378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.451888</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>6.070850</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>102.362243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean       -0.000005       0.000923      -0.000741      -0.000905   \n",
       "std         1.958196       1.646457       1.519870       1.414453   \n",
       "min       -56.407510     -72.715728     -48.325589      -5.683171   \n",
       "25%        -0.920445      -0.599402      -0.886796      -0.847125   \n",
       "50%         0.017150       0.064758       0.180478      -0.021181   \n",
       "75%         1.315281       0.803118       1.024676       0.740101   \n",
       "max         2.451888      22.057729       9.382558      16.875344   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean        0.000552       0.000855       0.000487       0.001346   \n",
       "std         1.383504       1.334153       1.242892       1.195017   \n",
       "min      -113.743307     -26.160506     -43.557242     -73.216718   \n",
       "25%        -0.690418      -0.769129      -0.552255      -0.208185   \n",
       "50%        -0.053246      -0.274624       0.040593       0.022513   \n",
       "75%         0.613955       0.399880       0.569928       0.327407   \n",
       "max        34.801666      73.301626     120.589494      20.007208   \n",
       "\n",
       "                  V9            V10      ...                  V20  \\\n",
       "count  227846.000000  227846.000000      ...        227846.000000   \n",
       "mean       -0.000260      -0.000595      ...            -0.000405   \n",
       "std         1.098315       1.089532      ...             0.772431   \n",
       "min       -13.434066     -24.588262      ...           -54.497720   \n",
       "25%        -0.643202      -0.535908      ...            -0.211726   \n",
       "50%        -0.052193      -0.093538      ...            -0.062041   \n",
       "75%         0.595389       0.452657      ...             0.133300   \n",
       "max        15.594995      23.745136      ...            39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean       -0.000189      -0.000028       0.000014      -0.000314   \n",
       "std         0.730943       0.725509       0.624362       0.605838   \n",
       "min       -34.830382     -10.933144     -44.807735      -2.836627   \n",
       "25%        -0.228490      -0.542285      -0.162012      -0.355164   \n",
       "50%        -0.029558       0.005874      -0.011262       0.040943   \n",
       "75%         0.186758       0.528388       0.147808       0.439268   \n",
       "max        27.202839      10.503090      22.528412       4.584549   \n",
       "\n",
       "                 V25            V26            V27            V28  \\\n",
       "count  227846.000000  227846.000000  227846.000000  227846.000000   \n",
       "mean       -0.000143       0.000866      -0.000005       0.000025   \n",
       "std         0.521485       0.482392       0.403746       0.329119   \n",
       "min       -10.295397      -2.604551     -22.565679     -15.430084   \n",
       "25%        -0.317216      -0.326270      -0.070937      -0.052962   \n",
       "50%         0.016064      -0.051559       0.001145       0.011201   \n",
       "75%         0.350726       0.241356       0.090591       0.078276   \n",
       "max         6.070850       3.517346      31.612198      33.847808   \n",
       "\n",
       "          normAmount  \n",
       "count  227846.000000  \n",
       "mean       -0.000050  \n",
       "std         1.007892  \n",
       "min        -0.353229  \n",
       "25%        -0.331110  \n",
       "50%        -0.265271  \n",
       "75%        -0.043378  \n",
       "max       102.362243  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For now we are not performing feature engineering, even though the data tends to show wide ranges with very sparse distribution on either ends. Data clipping could potentially improve the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization\n",
    "for feature in X_train.columns.values:\n",
    "    scalar = StandardScaler()\n",
    "    scalar.fit(X_train[feature].values.reshape(-1,1))\n",
    "    \n",
    "    X_train[feature] = scalar.transform(X_train[feature].values.reshape(-1,1))\n",
    "    X_test[feature] = scalar.transform(X_test[feature].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "      <td>2.278460e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.761354e-17</td>\n",
       "      <td>1.024922e-17</td>\n",
       "      <td>-1.166321e-17</td>\n",
       "      <td>-1.380726e-17</td>\n",
       "      <td>1.639222e-17</td>\n",
       "      <td>-1.932363e-17</td>\n",
       "      <td>1.469896e-17</td>\n",
       "      <td>-3.902781e-18</td>\n",
       "      <td>4.503535e-17</td>\n",
       "      <td>-5.732623e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.129845e-19</td>\n",
       "      <td>-7.258360e-18</td>\n",
       "      <td>-4.638704e-17</td>\n",
       "      <td>-1.406868e-18</td>\n",
       "      <td>4.876394e-17</td>\n",
       "      <td>-3.403063e-17</td>\n",
       "      <td>8.359588e-18</td>\n",
       "      <td>4.104754e-18</td>\n",
       "      <td>-1.013227e-17</td>\n",
       "      <td>-5.094052e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.880592e+01</td>\n",
       "      <td>-4.416563e+01</td>\n",
       "      <td>-3.179545e+01</td>\n",
       "      <td>-4.017298e+00</td>\n",
       "      <td>-8.221449e+01</td>\n",
       "      <td>-1.960901e+01</td>\n",
       "      <td>-3.504555e+01</td>\n",
       "      <td>-6.126963e+01</td>\n",
       "      <td>-1.223132e+01</td>\n",
       "      <td>-2.256723e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.055315e+01</td>\n",
       "      <td>-4.765113e+01</td>\n",
       "      <td>-1.506961e+01</td>\n",
       "      <td>-7.176585e+01</td>\n",
       "      <td>-4.681644e+00</td>\n",
       "      <td>-1.974222e+01</td>\n",
       "      <td>-5.401042e+00</td>\n",
       "      <td>-5.589086e+01</td>\n",
       "      <td>-4.688312e+01</td>\n",
       "      <td>-3.504147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.700459e-01</td>\n",
       "      <td>-3.646171e-01</td>\n",
       "      <td>-5.829816e-01</td>\n",
       "      <td>-5.982685e-01</td>\n",
       "      <td>-4.994358e-01</td>\n",
       "      <td>-5.771347e-01</td>\n",
       "      <td>-4.447234e-01</td>\n",
       "      <td>-1.753375e-01</td>\n",
       "      <td>-5.853909e-01</td>\n",
       "      <td>-4.913250e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.735804e-01</td>\n",
       "      <td>-3.123372e-01</td>\n",
       "      <td>-7.474174e-01</td>\n",
       "      <td>-2.595073e-01</td>\n",
       "      <td>-5.857188e-01</td>\n",
       "      <td>-6.080196e-01</td>\n",
       "      <td>-6.781534e-01</td>\n",
       "      <td>-1.756849e-01</td>\n",
       "      <td>-1.609955e-01</td>\n",
       "      <td>-3.284684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.760825e-03</td>\n",
       "      <td>3.877159e-02</td>\n",
       "      <td>1.192340e-01</td>\n",
       "      <td>-1.433533e-02</td>\n",
       "      <td>-3.888541e-02</td>\n",
       "      <td>-2.064828e-01</td>\n",
       "      <td>3.226887e-02</td>\n",
       "      <td>1.771253e-02</td>\n",
       "      <td>-4.728424e-02</td>\n",
       "      <td>-8.530616e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.979548e-02</td>\n",
       "      <td>-4.017971e-02</td>\n",
       "      <td>8.135577e-03</td>\n",
       "      <td>-1.805906e-02</td>\n",
       "      <td>6.810072e-02</td>\n",
       "      <td>3.107917e-02</td>\n",
       "      <td>-1.086759e-01</td>\n",
       "      <td>2.850188e-03</td>\n",
       "      <td>3.395697e-02</td>\n",
       "      <td>-2.631453e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716843e-01</td>\n",
       "      <td>4.872263e-01</td>\n",
       "      <td>6.746759e-01</td>\n",
       "      <td>5.238826e-01</td>\n",
       "      <td>4.433696e-01</td>\n",
       "      <td>2.990854e-01</td>\n",
       "      <td>4.581596e-01</td>\n",
       "      <td>2.728510e-01</td>\n",
       "      <td>5.423313e-01</td>\n",
       "      <td>4.160068e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.730962e-01</td>\n",
       "      <td>2.557618e-01</td>\n",
       "      <td>7.283396e-01</td>\n",
       "      <td>2.367139e-01</td>\n",
       "      <td>7.255797e-01</td>\n",
       "      <td>6.728287e-01</td>\n",
       "      <td>4.985381e-01</td>\n",
       "      <td>2.243901e-01</td>\n",
       "      <td>2.377603e-01</td>\n",
       "      <td>-4.298847e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.252122e+00</td>\n",
       "      <td>1.339656e+01</td>\n",
       "      <td>6.173764e+00</td>\n",
       "      <td>1.193131e+01</td>\n",
       "      <td>2.515437e+01</td>\n",
       "      <td>5.494193e+01</td>\n",
       "      <td>9.702314e+01</td>\n",
       "      <td>1.674111e+01</td>\n",
       "      <td>1.419929e+01</td>\n",
       "      <td>2.179448e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.103549e+01</td>\n",
       "      <td>3.721642e+01</td>\n",
       "      <td>1.447692e+01</td>\n",
       "      <td>3.608237e+01</td>\n",
       "      <td>7.567819e+00</td>\n",
       "      <td>1.164176e+01</td>\n",
       "      <td>7.289681e+00</td>\n",
       "      <td>7.829738e+01</td>\n",
       "      <td>1.028437e+02</td>\n",
       "      <td>1.015610e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05   \n",
       "mean  -2.761354e-17  1.024922e-17 -1.166321e-17 -1.380726e-17  1.639222e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -2.880592e+01 -4.416563e+01 -3.179545e+01 -4.017298e+00 -8.221449e+01   \n",
       "25%   -4.700459e-01 -3.646171e-01 -5.829816e-01 -5.982685e-01 -4.994358e-01   \n",
       "50%    8.760825e-03  3.877159e-02  1.192340e-01 -1.433533e-02 -3.888541e-02   \n",
       "75%    6.716843e-01  4.872263e-01  6.746759e-01  5.238826e-01  4.433696e-01   \n",
       "max    1.252122e+00  1.339656e+01  6.173764e+00  1.193131e+01  2.515437e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05   \n",
       "mean  -1.932363e-17  1.469896e-17 -3.902781e-18  4.503535e-17 -5.732623e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.960901e+01 -3.504555e+01 -6.126963e+01 -1.223132e+01 -2.256723e+01   \n",
       "25%   -5.771347e-01 -4.447234e-01 -1.753375e-01 -5.853909e-01 -4.913250e-01   \n",
       "50%   -2.064828e-01  3.226887e-02  1.771253e-02 -4.728424e-02 -8.530616e-02   \n",
       "75%    2.990854e-01  4.581596e-01  2.728510e-01  5.423313e-01  4.160068e-01   \n",
       "max    5.494193e+01  9.702314e+01  1.674111e+01  1.419929e+01  2.179448e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05   \n",
       "mean       ...      -6.129845e-19 -7.258360e-18 -4.638704e-17 -1.406868e-18   \n",
       "std        ...       1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...      -7.055315e+01 -4.765113e+01 -1.506961e+01 -7.176585e+01   \n",
       "25%        ...      -2.735804e-01 -3.123372e-01 -7.474174e-01 -2.595073e-01   \n",
       "50%        ...      -7.979548e-02 -4.017971e-02  8.135577e-03 -1.805906e-02   \n",
       "75%        ...       1.730962e-01  2.557618e-01  7.283396e-01  2.367139e-01   \n",
       "max        ...       5.103549e+01  3.721642e+01  1.447692e+01  3.608237e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05  2.278460e+05   \n",
       "mean   4.876394e-17 -3.403063e-17  8.359588e-18  4.104754e-18 -1.013227e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.681644e+00 -1.974222e+01 -5.401042e+00 -5.589086e+01 -4.688312e+01   \n",
       "25%   -5.857188e-01 -6.080196e-01 -6.781534e-01 -1.756849e-01 -1.609955e-01   \n",
       "50%    6.810072e-02  3.107917e-02 -1.086759e-01  2.850188e-03  3.395697e-02   \n",
       "75%    7.255797e-01  6.728287e-01  4.985381e-01  2.243901e-01  2.377603e-01   \n",
       "max    7.567819e+00  1.164176e+01  7.289681e+00  7.829738e+01  1.028437e+02   \n",
       "\n",
       "         normAmount  \n",
       "count  2.278460e+05  \n",
       "mean  -5.094052e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.504147e-01  \n",
       "25%   -3.284684e-01  \n",
       "50%   -2.631453e-01  \n",
       "75%   -4.298847e-02  \n",
       "max    1.015610e+02  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 28*4))\n",
    "# gs = gridspec.GridSpec(28, 1)\n",
    "# for i, cn in enumerate (X_train.columns.values):\n",
    "#     ax = plt.subplot(gs[i])  # add a new plot\n",
    "#     sns.distplot( X_train[cn].loc[y_train == 1], bins = 50)\n",
    "#     sns.distplot( X_train[cn].loc[y_train == 0], bins = 50)\n",
    "#     ax.set_xlabel(\"\")  # to avoid overlapping\n",
    "#     ax.set_title(\"Feature\" + str(i))\n",
    "#     ax.set_xlim(-10, 10)  # set limits to identify features of similar distributions\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_val, y_train_, y_val_ = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array for Tensorflow\n",
    "\n",
    "inputX = X_train_.values\n",
    "inputY = y_train_.values\n",
    "\n",
    "inputX_valid = X_val.values\n",
    "inputY_valid = y_val_.values\n",
    "\n",
    "inputX_test = X_test.values\n",
    "inputY_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182276, 29)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(inputX)\n",
    "inputX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_nodes = 29\n",
    "# multiplier = 1.5\n",
    "\n",
    "# hidden1 = 20\n",
    "# hidden2 = round(hidden1 * multiplier)\n",
    "# hidden3 = round(hidden2 * multiplier)\n",
    "\n",
    "# pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# x = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "\n",
    "# # layer 1\n",
    "# W_1 = tf.Variable(tf.truncated_normal([input_nodes, hidden1]), stddev = 0.15)\n",
    "# b_1 = tf.Variable(tf.zeros([hidden1]))\n",
    "# y_1 = tf.nn.relu( tf.add(tf.matmul(  x, W_1), b1) )\n",
    "\n",
    "# # layer 2\n",
    "# W_2 = tf.Variable(tf.truncated_normal([hidden1, hidden2]), stddev = 0.15)\n",
    "# b_2 = tf.Variable(tf.zeros([hidden2]))\n",
    "# y_2 = tf.nn.relu( tf.add(tf.matmul(y_1, W_2), b2) )\n",
    "\n",
    "# # layer 3\n",
    "# W_3 = tf.Variable(tf.truncated_normal([hidden2, hidden3]), stddev = 0.15)\n",
    "# b_3 = tf.Variable(tf.zeros([hidden3]))\n",
    "# y_3 = tf.nn.relu( tf.add(tf.matmul(y_2, W_3), b3) )\n",
    "\n",
    "# # layer 4\n",
    "# W_4 = tf.Variable(tf.truncated_normal([hidden3, 2]), stddev = 0.15)\n",
    "# b_4 = tf.Variable(tf.zeros([2]))\n",
    "# y_4 = tf.nn.relu( tf.add(tf.matmul(y_3, W4), b4) )\n",
    "\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following is based on exercise 8 from chapter 11 of Hands on machine learning with sklearn and TF\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers = 3, n_neurons = 20, name = None, activation =\n",
    "        tf.nn.elu, initializer = he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range (n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation= activation,\n",
    "                                    kernel_initializer = initializer,\n",
    "                                    name = \"hidden%d\" % (layer+1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 29 \n",
    "n_outputs = 2\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=(None, n_inputs), name = \"X\")\n",
    "y= tf.placeholder(tf.int32, shape=(None), name= \"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer= he_init, \n",
    "                        name = \"logits\")\n",
    "\n",
    "Y_proba = tf.nn.softmax(logits, name = \"Y_proba\")\n",
    "\n",
    "Y_proba_bin = tf.round(Y_proba) # jgwei, use 0.5 as decision boundary\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits= logits)\n",
    "\n",
    "# Y_proba = tf.nn.sigmoid(logits, name = \"Y_proba\")\n",
    "# xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels= tf.cast(y, tf.float32), logits= logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name = \"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "training_op = optimizer.minimize(loss, name = \"training_op\")\n",
    "\n",
    "# correct = tf.nn.in_top_k(logits, y, 1)\n",
    "correct = tf.nn.in_top_k(Y_proba_bin, y, 1)  # jgwei\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name = \"accuracy\")\n",
    "\n",
    "Y_proba_bin_decoded = tf.argmax(Y_proba_bin, axis = 1)\n",
    "roc_score = tf.metrics.auc(y, Y_proba_bin_decoded)\n",
    "\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) # local var init also needed\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_wo_prog = 20\n",
    "checks_wo_prg = 0\n",
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.006430\tBest loss: 0.006430\tAccuracy: 99.93%\n",
      "Predicted Y_proba_bin_decode:[0 0 0 ... 0 0 0]\n",
      "\n",
      "1\tValidation loss: 0.008956\tBest loss: 0.006430\tAccuracy: 99.92%\n",
      "Predicted Y_proba_bin_decode:[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6804a125749c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_proba_bin_decoded_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_proba_bin_decoded\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputY_valid\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#             loss_val, acc_val, roc_score_val, Y_proba_bin_val = sess.run([loss, accuracy, roc_score, Y_proba_bin], feed_dict={X: inputX_valid, y: inputY_valid})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        rnd_idx = np.random.permutation(len(inputX)) # permute input examples\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(inputX) // batch_size):\n",
    "            X_batch, y_batch = inputX[rnd_indices], inputY[rnd_indices]\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "            loss_val, acc_val, Y_proba_bin_decoded_val = sess.run([loss, accuracy, Y_proba_bin_decoded], feed_dict={X: inputX_valid, y: inputY_valid})\n",
    "#             loss_val, acc_val, roc_score_val, Y_proba_bin_val = sess.run([loss, accuracy, roc_score, Y_proba_bin], feed_dict={X: inputX_valid, y: inputY_valid})\n",
    "            \n",
    "\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./kaggle_creditcard_fraud_model.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_wo_prg = 0\n",
    "        else:\n",
    "            checks_wo_prg += 1\n",
    "            if checks_wo_prg > max_checks_wo_prog:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "        print (\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "        epoch, loss_val, best_loss, acc_val * 100))\n",
    "#         print (\"Predicted Y_proba_bin_decode:{}\\n\".format\n",
    "#                (Y_proba_bin_decoded_val))\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./kaggle_creditcard_fraud_model.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: inputX_valid, y: inputY_valid})\n",
    "    print (\"Final test accuracy: {:.2f}%\".format(acc_test * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./kaggle_creditcard_fraud_model.ckpt\n",
      "Final test accuracy: 99.93%\n",
      "ROC train:  (0.0, 0.90509963)\n",
      "ROC test:  (0.90509963, 0.89590985)\n"
     ]
    }
   ],
   "source": [
    "# debug with existing model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    saver.restore(sess, \"./kaggle_creditcard_fraud_model.ckpt\")\n",
    "    \n",
    "    acc_test = accuracy.eval(feed_dict={X: inputX_test, y: inputY_test})\n",
    "    print (\"Test accuracy: {:.2f}%\".format(acc_test * 100.))\n",
    "    ##### roc_score is a tuple, cannot use \"eval\" method\n",
    "    roc_score_train = sess.run(roc_score, feed_dict={X: inputX, y: inputY}) \n",
    "    print(\"ROC train: \", roc_score_train)\n",
    "    roc_score_test = sess.run(roc_score, feed_dict={X: inputX_test, y: inputY_test}) \n",
    "    print(\"ROC test: \", roc_score_test)\n",
    "#     print (\"ROC: {:.2f}\".format(roc_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
